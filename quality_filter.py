import re
import logging
from langchain.docstore.document import Document
from typing import List, Dict, Any, Tuple

logger = logging.getLogger(__name__)

# å®‰å…¨é¢†åŸŸå…³é”®è¯
SECURITY_KEYWORDS = {
    # ä¸­æ–‡å…³é”®è¯
    'chinese': [
        'APT', 'æ”»å‡»', 'å¨èƒ', 'æ¶æ„', 'æ¼æ´', 'ç—…æ¯’', 'æœ¨é©¬', 'åé—¨',
        'é’“é±¼', 'é—´è°', 'æ¸—é€', 'å…¥ä¾µ', 'ç»„ç»‡', 'æ´»åŠ¨', 'æŠ€æœ¯', 'æˆ˜æœ¯',
        'å·¥å…·', 'æµç¨‹', 'æ ·æœ¬', 'åˆ†æ', 'æ£€æµ‹', 'é˜²å¾¡', 'å“åº”', 'æƒ…æŠ¥',
        'é»‘å®¢', 'ç½‘ç»œ', 'å®‰å…¨', 'æ•°æ®', 'æ³„éœ²', 'å‹’ç´¢', 'è½¯ä»¶', 'æ¶æ„ä»£ç ',
        'åƒµå°¸ç½‘ç»œ', 'å‘½ä»¤æ§åˆ¶', 'æ¨ªå‘ç§»åŠ¨', 'æƒé™æå‡', 'æŒä¹…åŒ–', 'æ•°æ®æ”¶é›†',
        'æ•°æ®çªƒå–', 'ç ´å', 'å½±å“', 'ç›®æ ‡', 'å—å®³è€…', 'è½½è·', 'æŠ•é€’',
        'æ‰§è¡Œ', 'é€šä¿¡', 'éšè”½', 'ä¼ªè£…', 'ç»•è¿‡', 'è§„é¿', 'ç›‘æ§', 'æ—¥å¿—'
    ],
    # è‹±æ–‡å…³é”®è¯
    'english': [
        'attack', 'threat', 'malicious', 'malware', 'vulnerability', 'exploit',
        'backdoor', 'trojan', 'virus', 'phishing', 'spear', 'espionage',
        'infiltration', 'penetration', 'intrusion', 'breach', 'compromise',
        'payload', 'C2', 'command', 'control', 'RAT', 'botnet', 'dropper',
        'loader', 'downloader', 'implant', 'backdoor', 'rootkit', 'keylogger',
        'stealer', 'ransomware', 'wiper', 'cryptor', 'packer', 'obfuscator',
        'reconnaissance', 'initial', 'access', 'execution', 'persistence',
        'privilege', 'escalation', 'defense', 'evasion', 'credential',
        'discovery', 'lateral', 'movement', 'collection', 'exfiltration',
        'impact', 'command', 'control', 'communication',
        'actor', 'group', 'campaign', 'operation', 'mission', 'target',
        'victim', 'infrastructure', 'domain', 'IP', 'hash', 'indicator',
        'IOC', 'TTPs', 'tactics', 'techniques', 'procedures', 'tools',
        'sample', 'binary', 'executable', 'script', 'shellcode', 'injection',
        'hooking', 'hijacking', 'spoofing', 'masquerading', 'living',
        'fileless', 'memory', 'registry', 'process', 'service', 'task',
        'scheduled', 'startup', 'autostart', 'persistence', 'steganography',
        'network', 'protocol', 'traffic', 'packet', 'connection', 'session',
        'tunnel', 'proxy', 'gateway', 'firewall', 'IDS', 'IPS', 'SIEM',
        'endpoint', 'host', 'server', 'client', 'browser', 'email',
        'analysis', 'forensic', 'investigation', 'detection', 'hunting',
        'monitoring', 'logging', 'signature', 'rule', 'alert', 'event',
        'intelligence', 'attribution', 'clustering', 'correlation'
    ]
}


class QualityFilter:
    """å†…å®¹è´¨é‡è¿‡æ»¤å™¨ - è¿‡æ»¤å¯¼èˆªèœå•ã€è¥é”€å†…å®¹ç­‰ä½è´¨é‡chunks"""

    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–è´¨é‡è¿‡æ»¤å™¨"""
        quality_config = config.get('quality_filter', {})
        self.min_quality_score = quality_config.get('min_quality_score', 60)
        self.enable_quality_filter = quality_config.get(
            'enable_quality_filter', True)

    def filter_chunks(self, chunks: List[Document]) -> List[Document]:
        """è¿‡æ»¤ä½è´¨é‡chunks"""
        if not self.enable_quality_filter:
            return chunks, None

        filtered_chunks = []
        navigation_count = 0
        marketing_count = 0
        low_quality_count = 0

        # å­˜å‚¨è¢«è¿‡æ»¤çš„chunksä¿¡æ¯
        filtered_chunks_info = []

        for chunk in chunks:
            content = getattr(chunk, 'page_content', str(chunk))

            # ğŸ”¥ ä¼˜å…ˆè¿›è¡Œå¿«é€Ÿè¿‡æ»¤æ£€æŸ¥
            if self._is_navigation_menu(content):
                navigation_count += 1
                logger.debug(f"âŒ å¯¼èˆªèœå•å†…å®¹è¢«è¿‡æ»¤")
                # è®°å½•è¢«è¿‡æ»¤çš„chunkä¿¡æ¯
                filtered_chunks_info.append({
                    'type': 'navigation_menu',
                    'content': content[:200] + "..." if len(content) > 200 else content,
                    'metadata': getattr(chunk, 'metadata', {}),
                    'reason': 'å¯¼èˆªèœå•å†…å®¹'
                })
                continue

            if self._is_marketing_content(content):
                marketing_count += 1
                logger.debug(f"âŒ è¥é”€å†…å®¹è¢«è¿‡æ»¤")
                # è®°å½•è¢«è¿‡æ»¤çš„chunkä¿¡æ¯
                filtered_chunks_info.append({
                    'type': 'marketing_content',
                    'content': content[:200] + "..." if len(content) > 200 else content,
                    'metadata': getattr(chunk, 'metadata', {}),
                    'reason': 'è¥é”€æ¨å¹¿å†…å®¹'
                })
                continue

            # è¯¦ç»†è´¨é‡è¯„åˆ†
            quality_score, issues = self.calculate_quality_score(content)

            if quality_score >= self.min_quality_score:
                filtered_chunks.append(chunk)
            else:
                low_quality_count += 1
                # è·å–å†…å®¹çš„å‰100ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆ
                content_preview = content[:100] + \
                    "..." if len(content) > 100 else content
                logger.info(
                    f"âŒ ä½è´¨é‡å†…å®¹è¢«è¿‡æ»¤ (åˆ†æ•°: {quality_score}, é—®é¢˜: {issues})")
                logger.debug(
                    f"   å†…å®¹é¢„è§ˆ: {content_preview}")

                # è®°å½•è¢«è¿‡æ»¤çš„chunkä¿¡æ¯
                filtered_chunks_info.append({
                    'type': 'low_quality',
                    'content': content,
                    'metadata': getattr(chunk, 'metadata', {}),
                    'quality_score': quality_score,
                    'issues': issues
                })

        logger.info(f"ğŸ” è´¨é‡è¿‡æ»¤å®Œæˆ: {len(chunks)} -> {len(filtered_chunks)}ä¸ªchunk")
        logger.info(
            f"   è¿‡æ»¤ç»Ÿè®¡: å¯¼èˆªèœå•{navigation_count}ä¸ª, è¥é”€å†…å®¹{marketing_count}ä¸ª, ä½è´¨é‡{low_quality_count}ä¸ª")

        return filtered_chunks, filtered_chunks_info

    def calculate_quality_score(self, content: str, content_type: str = 'text') -> Tuple[int, List[str]]:
        """è®¡ç®—å†…å®¹è´¨é‡åˆ†æ•°"""
        issues = []
        score = 100

        # åŸºç¡€æ£€æŸ¥
        if len(content.strip()) < 50:
            score -= 40
            issues.append("å†…å®¹è¿‡çŸ­")
            return max(0, score), issues

        # ä¹±ç æ£€æµ‹
        if self._is_garbled_text(content):
            score -= 80
            issues.append("æ£€æµ‹åˆ°ä¹±ç å†…å®¹")
            return max(0, score), issues

        # çº¯æ ‡é¢˜æ£€æµ‹
        if self._is_title_only(content):
            score -= 40
            issues.append("ä»…åŒ…å«æ ‡é¢˜")

        # è¯­è¨€å†…å®¹æ£€æŸ¥
        lang_score, lang_issues = self._check_language_content(content)
        score += lang_score
        issues.extend(lang_issues)

        # å®‰å…¨å…³é”®è¯æ£€æŸ¥
        keyword_score, keyword_issues = self._check_security_keywords(content)
        score += keyword_score
        issues.extend(keyword_issues)

        # å®è´¨å†…å®¹æ£€æŸ¥
        substance_score, substance_issues = self._check_content_substance(
            content)
        score += substance_score
        issues.extend(substance_issues)

        # è¡¨æ ¼ç‰¹æ®Šæ£€æŸ¥
        if content_type == 'table':
            table_score, table_issues = self._check_table_quality(content)
            score += table_score
            issues.extend(table_issues)

        # æŠ€æœ¯æŒ‡æ ‡åŠ åˆ†
        tech_bonus = self._get_technical_bonus(content)
        score += tech_bonus
        if tech_bonus > 0:
            issues.append(f"åŒ…å«æŠ€æœ¯æŒ‡æ ‡ (+{tech_bonus}åˆ†)")

        return max(0, min(100, score)), issues

    def _is_navigation_menu(self, content: str) -> bool:
        """ğŸ”¥ å¢å¼ºï¼šæ£€æµ‹å¯¼èˆªèœå•å†…å®¹"""
        # æ£€æµ‹é“¾æ¥å¯†åº¦
        link_pattern = r'\[([^\]]+)\]\([^)]+\)'
        links = re.findall(link_pattern, content)
        lines = [line.strip() for line in content.split('\n') if line.strip()]

        if not lines:
            return False

        # é“¾æ¥å¯†åº¦è¶…è¿‡60%åˆ¤å®šä¸ºå¯¼èˆª
        link_density = len(links) / len(lines) if lines else 0
        if link_density > 0.6:
            return True

        # æ£€æµ‹é‡å¤å¯¼èˆªæ¨¡å¼
        nav_patterns = [
            r'^[+*-]\s*\[([^\]]+)\]\([^)]+\)',  # + [äº§å“](/è·¯å¾„/)
            r'^\s*\[([^\]]+)\]\([^)]+\)\s*$',   # [äº§å“](/è·¯å¾„/)
        ]

        nav_line_count = 0
        for line in lines:
            for pattern in nav_patterns:
                if re.match(pattern, line):
                    nav_line_count += 1
                    break

        # å¯¼èˆªé¡¹è¶…è¿‡8ä¸ªåˆ¤å®šä¸ºå¯¼èˆªèœå•
        if nav_line_count > 8:
            return True

        # æ£€æµ‹äº§å“/æœåŠ¡åˆ—è¡¨æ¨¡å¼
        product_indicators = [
            r'Products?\s*$', r'Services?\s*$', r'Solutions?\s*$',
            r'Learn more', r'Explore solutions', r'Free Tools'
        ]

        indicator_count = sum(1 for pattern in product_indicators
                              for line in lines
                              if re.search(pattern, line, re.IGNORECASE))

        # æœ‰äº§å“æŒ‡æ ‡ä¸”é“¾æ¥å¤šçš„å†…å®¹
        if indicator_count >= 2 and len(links) > 5:
            return True

        return False

    def _is_marketing_content(self, content: str) -> bool:
        """æ£€æµ‹è¥é”€æ¨å¹¿å†…å®¹"""
        marketing_indicators = [
            r'Contact.*sales', r'Talk to sales', r'Get.*assistance',
            r'Join.*Club', r'Subscribe', r'fill.*form', r'representative.*contact',
            r'24/7.*response', r'Learn more', r'Explore.*solutions'
        ]

        marketing_count = sum(1 for pattern in marketing_indicators
                              if re.search(pattern, content, re.IGNORECASE))

        # è¥é”€æŒ‡æ ‡è¶…è¿‡2ä¸ªåˆ¤å®šä¸ºè¥é”€å†…å®¹
        return marketing_count >= 2

    def _is_garbled_text(self, content: str) -> bool:
        """æ£€æµ‹ä¹±ç å†…å®¹"""
        # æ£€æµ‹é•¿ç¼–ç å­—ç¬¦ä¸²
        if re.search(r'[a-zA-Z0-9+/=]{50,}', content):
            return True

        # æ£€æµ‹å­—ç¬¦åˆ†å¸ƒå¼‚å¸¸
        total_chars = len(content)
        if total_chars > 100:
            spaces = content.count(' ')
            punctuation = len(re.findall(r'[.,;:!?()[\]{}"]', content))

            space_ratio = spaces / total_chars
            punct_ratio = punctuation / total_chars

            # ç¼ºä¹æ­£å¸¸çš„ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†å¸ƒ
            if space_ratio < 0.05 and punct_ratio < 0.02:
                return True

        return False

    def _is_title_only(self, content: str) -> bool:
        """æ£€æµ‹ä»…åŒ…å«æ ‡é¢˜çš„å†…å®¹"""
        lines = [line.strip() for line in content.split('\n') if line.strip()]

        if len(lines) <= 2:
            content_clean = content.strip()
            # æ£€æµ‹æ ‡é¢˜æ¨¡å¼
            title_patterns = [
                r'^#+\s+', r'^.*\n[-=]+$', r'^\s*[A-Z][^.!?]*$'
            ]

            for pattern in title_patterns:
                if re.search(pattern, content_clean, re.MULTILINE):
                    return True

            # çŸ­å†…å®¹ä¸”æ— å¥å·
            if len(content_clean) < 100 and '.' not in content_clean:
                return True

        return False

    def _check_language_content(self, content: str) -> Tuple[int, List[str]]:
        """æ£€æŸ¥è¯­è¨€å†…å®¹è´¨é‡"""
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', content))
        english_chars = len(re.findall(r'[a-zA-Z]', content))
        total_chars = len(content)

        if total_chars == 0:
            return -30, ["å†…å®¹ä¸ºç©º"]

        chinese_ratio = chinese_chars / total_chars
        english_ratio = english_chars / total_chars

        # ç¼ºä¹æœ‰æ•ˆæ–‡å­—å†…å®¹
        if chinese_ratio < 0.1 and english_ratio < 0.3:
            return -25, ["ç¼ºä¹æœ‰æ•ˆæ–‡å­—å†…å®¹"]

        # æ•°å­—ç¬¦å·æ¯”ä¾‹è¿‡é«˜
        digit_symbol_chars = len(re.findall(r'[\d\|\-\+\.\s]', content))
        digit_ratio = digit_symbol_chars / total_chars

        if digit_ratio > 0.6:
            return -15, ["æ•°å­—ç¬¦å·æ¯”ä¾‹è¿‡é«˜"]

        return 0, []

    def _check_security_keywords(self, content: str) -> Tuple[int, List[str]]:
        """æ£€æŸ¥å®‰å…¨å…³é”®è¯"""
        content_lower = content.lower()

        # ç»Ÿè®¡å…³é”®è¯
        chinese_keywords = sum(1 for kw in SECURITY_KEYWORDS['chinese']
                               if kw.lower() in content_lower)
        english_keywords = sum(1 for kw in SECURITY_KEYWORDS['english']
                               if re.search(r'\b' + re.escape(kw.lower()) + r'\b', content_lower))

        total_keywords = chinese_keywords + english_keywords

        # è¯„åˆ†ç­–ç•¥
        if total_keywords < 2:
            return -15, [f"å®‰å…¨å…³é”®è¯ä¸è¶³ (æ€»è®¡: {total_keywords})"]
        elif total_keywords < 4:
            return -5, [f"å®‰å…¨å…³é”®è¯åå°‘ (æ€»è®¡: {total_keywords})"]
        else:
            return 5, [f"å®‰å…¨å…³é”®è¯å……è¶³ (æ€»è®¡: {total_keywords})"]

    def _check_content_substance(self, content: str) -> Tuple[int, List[str]]:
        """æ£€æŸ¥å†…å®¹å®è´¨æ€§"""
        # å»é™¤é“¾æ¥åçš„çº¯æ–‡æœ¬
        text_without_links = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', content)
        pure_text = re.sub(r'[+*-]\s*', '', text_without_links)
        pure_text_length = len(
            [c for c in pure_text if c.isalnum() or c.isspace()])

        # å®è´¨å†…å®¹é•¿åº¦æ£€æŸ¥
        if pure_text_length < 100:
            return -20, [f"å®è´¨å†…å®¹ä¸è¶³ ({pure_text_length}å­—ç¬¦)"]
        elif pure_text_length < 200:
            return -10, [f"å®è´¨å†…å®¹è¾ƒå°‘ ({pure_text_length}å­—ç¬¦)"]
        else:
            return 5, [f"å®è´¨å†…å®¹å……è¶³ ({pure_text_length}å­—ç¬¦)"]

    def _check_table_quality(self, content: str) -> Tuple[int, List[str]]:
        """æ£€æŸ¥è¡¨æ ¼è´¨é‡"""
        issues = []
        score = 0

        # è¡¨æ ¼å®ä½“å…³é”®è¯
        table_keywords = [
            'APT', 'ç»„ç»‡', 'æ”»å‡»', 'æŠ€æœ¯', 'å·¥å…·', 'æ ·æœ¬', 'å®¶æ—', 'group',
            'actor', 'family', 'campaign', 'hash', 'domain', 'IP'
        ]

        keyword_count = sum(1 for kw in table_keywords
                            if kw.lower() in content.lower())

        if keyword_count < 2:
            score -= 15
            issues.append(f"è¡¨æ ¼å®ä½“å…³é”®è¯ä¸è¶³ ({keyword_count})")

        # è¡¨æ ¼ç»“æ„æ£€æŸ¥
        table_lines = [line for line in content.split('\n')
                       if line.strip().startswith('|')]

        if len(table_lines) < 3:
            score -= 10
            issues.append("è¡¨æ ¼ç»“æ„ä¸å®Œæ•´")
        else:
            # åˆ—æ•°æ£€æŸ¥
            avg_columns = sum(len(line.split('|'))
                              for line in table_lines) / len(table_lines)
            if avg_columns < 3:
                score -= 5
                issues.append("è¡¨æ ¼ä¿¡æ¯å¯†åº¦ä½")

        return score, issues

    def _get_technical_bonus(self, content: str) -> int:
        """è·å–æŠ€æœ¯æŒ‡æ ‡åŠ åˆ†"""
        technical_patterns = [
            r'\b[a-fA-F0-9]{32}\b',            # MD5
            r'\b[a-fA-F0-9]{40}\b',            # SHA1
            r'\b[a-fA-F0-9]{64}\b',            # SHA256
            r'\b(?:\d{1,3}\.){3}\d{1,3}\b',    # IPåœ°å€
            r'\b[a-zA-Z0-9-]+\.[a-zA-Z]{2,}\b',  # åŸŸå
            r'\bCVE-\d{4}-\d{4,}\b',           # CVEç¼–å·
            r'\bT\d{4}(?:\.\d{3})?\b',         # ATT&CKæŠ€æœ¯ç¼–å·
            r'\b0x[a-fA-F0-9]+\b',             # åå…­è¿›åˆ¶åœ°å€
        ]

        technical_count = sum(1 for pattern in technical_patterns
                              if re.search(pattern, content))

        return min(technical_count * 2, 10)  # æœ€å¤šåŠ 10åˆ†
