# coding:utf-8
"""
QAå¯¹ç”Ÿæˆæ¨¡å— - åŸºäºæ–‡æ¡£chunksç”Ÿæˆé—®ç­”å¯¹
"""
import logging
import json
import time
from typing import List, Dict, Any, Optional
from langchain.docstore.document import Document
from utils import OpenAIAPIManager, GPTResponseParser
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)


class QAGenerator:
    """QAå¯¹ç”Ÿæˆå™¨ - ä¸ºæ¯ä¸ªchunkç”Ÿæˆé—®ç­”å¯¹"""

    def __init__(self, config: Dict[str, Any], api_manager: OpenAIAPIManager):
        """
        åˆå§‹åŒ–QAç”Ÿæˆå™¨

        Args:
            config: QAç”Ÿæˆé…ç½®
            api_manager: APIç®¡ç†å™¨å®ä¾‹
        """
        self.config = config
        self.api_manager = api_manager

        # ä»é…ç½®ä¸­è¯»å–å‚æ•°
        self.qa_per_chunk = config.get('qa_per_chunk', 3)
        self.batch_size = config.get('batch_size', 5)
        self.max_workers = config.get('max_workers', 3)
        self.enable_threading = config.get('enable_threading', True)
        self.answer_language = config.get('answer_language', 'chinese')
        self.question_types = config.get(
            'question_types', ['factual', 'analytical', 'inferential'])

        logger.info(f"ğŸ¤– QAç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ - æ¯chunkç”Ÿæˆ{self.qa_per_chunk}ä¸ªQAå¯¹")

    def generate_qa_for_chunks(self, chunks: List[Document], max_chunks: int = None) -> List[Dict[str, Any]]:
        """
        ä¸ºæ‰€æœ‰chunksç”ŸæˆQAå¯¹

        Args:
            chunks: æ–‡æ¡£å—åˆ—è¡¨
            max_chunks: æœ€å¤§å¤„ç†æ•°é‡

        Returns:
            åŒ…å«QAå¯¹çš„ç»“æœåˆ—è¡¨
        """
        logger.info(f"ğŸš€ å¼€å§‹ä¸º{len(chunks)}ä¸ªchunksç”ŸæˆQAå¯¹")

        if max_chunks:
            chunks = chunks[:max_chunks]
            logger.info(f"ğŸ“ é™åˆ¶å¤„ç†æ•°é‡ä¸º{max_chunks}ä¸ªchunks")

        results = []
        start_time = time.time()

        if self.enable_threading and len(chunks) > 1:
            results = self._generate_qa_parallel(chunks)
        else:
            results = self._generate_qa_sequential(chunks)

        total_time = time.time() - start_time
        total_qa_pairs = sum(len(result.get('qa_pairs', []))
                             for result in results)

        logger.info(f"âœ… QAç”Ÿæˆå®Œæˆï¼")
        logger.info(f"   - å¤„ç†chunks: {len(chunks)}ä¸ª")
        logger.info(f"   - ç”ŸæˆQAå¯¹: {total_qa_pairs}ä¸ª")
        logger.info(f"   - æ€»è€—æ—¶: {total_time:.2f}ç§’")
        logger.info(f"   - å¹³å‡é€Ÿåº¦: {total_qa_pairs/total_time:.2f}ä¸ªQAå¯¹/ç§’")

        return results

    def _generate_qa_sequential(self, chunks: List[Document]) -> List[Dict[str, Any]]:
        """é¡ºåºç”ŸæˆQAå¯¹"""
        results = []

        for i, chunk in enumerate(chunks, 1):
            logger.info(f"ğŸ“ å¤„ç†ç¬¬{i}/{len(chunks)}ä¸ªchunk")
            result = self._generate_qa_for_single_chunk(chunk, i)
            results.append(result)

        return results

    def _generate_qa_parallel(self, chunks: List[Document]) -> List[Dict[str, Any]]:
        """å¹¶è¡Œç”ŸæˆQAå¯¹"""
        results = [None] * len(chunks)

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {
                executor.submit(self._generate_qa_for_single_chunk, chunk, i+1): i
                for i, chunk in enumerate(chunks)
            }

            # æ”¶é›†ç»“æœ
            completed = 0
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                completed += 1

                try:
                    result = future.result()
                    results[index] = result
                    logger.info(
                        f"âœ… å®Œæˆç¬¬{index+1}ä¸ªchunk QAç”Ÿæˆ ({completed}/{len(chunks)})")

                except Exception as e:
                    logger.error(f"âŒ ç¬¬{index+1}ä¸ªchunk QAç”Ÿæˆå¤±è´¥: {e}")
                    results[index] = {
                        'chunk_index': index + 1,
                        'status': 'failed',
                        'error': str(e),
                        'qa_pairs': []
                    }

        return results

    def _generate_qa_for_single_chunk(self, chunk: Document, chunk_index: int) -> Dict[str, Any]:
        """ä¸ºå•ä¸ªchunkç”ŸæˆQAå¯¹"""
        try:
            content = chunk.page_content
            metadata = chunk.metadata

            # æ£€æŸ¥å†…å®¹é•¿åº¦
            if len(content.strip()) < 50:
                logger.warning(f"âš ï¸ ç¬¬{chunk_index}ä¸ªchunkå†…å®¹è¿‡çŸ­ï¼Œè·³è¿‡QAç”Ÿæˆ")
                return {
                    'chunk_index': chunk_index,
                    'status': 'skipped',
                    'reason': 'content_too_short',
                    'qa_pairs': [],
                    'chunk_metadata': metadata
                }

            # æ„å»ºæç¤ºè¯
            prompt = self._build_qa_generation_prompt(content)

            # è°ƒç”¨APIç”ŸæˆQAå¯¹
            messages = [
                {"role": "system", "content": self._get_system_prompt()},
                {"role": "user", "content": prompt}
            ]

            response = self.api_manager.call_api(
                messages=messages,
                temperature=0.7,
                max_tokens=2000
            )

            # è§£æå“åº”
            qa_pairs = self._parse_qa_response(response, chunk_index)

            return {
                'chunk_index': chunk_index,
                'status': 'success',
                'qa_pairs': qa_pairs,
                'chunk_content': content,
                'chunk_metadata': metadata,
                'api_response': response
            }

        except Exception as e:
            logger.error(f"âŒ ç¬¬{chunk_index}ä¸ªchunk QAç”Ÿæˆå¼‚å¸¸: {e}")
            return {
                'chunk_index': chunk_index,
                'status': 'failed',
                'error': str(e),
                'qa_pairs': [],
                'chunk_metadata': metadata
            }

    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        language_instruction = {
            'chinese': 'è¯·ç”¨ä¸­æ–‡å›ç­”',
            'english': 'Please answer in English',
            'bilingual': 'è¯·ç”¨ä¸­è‹±æ–‡åŒè¯­å›ç­”'
        }.get(self.answer_language, 'è¯·ç”¨ä¸­æ–‡å›ç­”')

        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”å¯¹ç”Ÿæˆä¸“å®¶ã€‚

ä»»åŠ¡ï¼šæ ¹æ®ç»™å®šçš„æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆé«˜è´¨é‡çš„é—®ç­”å¯¹ã€‚

è¦æ±‚ï¼š
1. ç”Ÿæˆ{self.qa_per_chunk}ä¸ªä¸åŒç±»å‹çš„é—®ç­”å¯¹
2. é—®é¢˜ç±»å‹åŒ…æ‹¬ï¼šäº‹å®æ€§é—®é¢˜ã€åˆ†ææ€§é—®é¢˜ã€æ¨ç†æ€§é—®é¢˜
3. é—®é¢˜è¦å…·ä½“ã€æ¸…æ™°ï¼Œé¿å…è¿‡äºå®½æ³›
4. ç­”æ¡ˆè¦å‡†ç¡®ã€å®Œæ•´ï¼ŒåŸºäºæ–‡æ¡£å†…å®¹
5. {language_instruction}
6. ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡º

è¾“å‡ºæ ¼å¼ï¼š
{{
    "qa_pairs": [
        {{
            "question": "å…·ä½“é—®é¢˜",
            "answer": "è¯¦ç»†ç­”æ¡ˆ",
            "type": "factual|analytical|inferential",
            "confidence": 0.85
        }}
    ]
}}"""

    def _build_qa_generation_prompt(self, content: str) -> str:
        """æ„å»ºQAç”Ÿæˆæç¤ºè¯"""
        return f"""è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹ç”Ÿæˆ{self.qa_per_chunk}ä¸ªé«˜è´¨é‡é—®ç­”å¯¹ï¼š

ã€æ–‡æ¡£å†…å®¹ã€‘
{content}

ã€ç”Ÿæˆè¦æ±‚ã€‘
- ç”Ÿæˆ{self.qa_per_chunk}ä¸ªé—®ç­”å¯¹
- åŒ…å«ä¸åŒç±»å‹çš„é—®é¢˜ï¼ˆäº‹å®æ€§ã€åˆ†ææ€§ã€æ¨ç†æ€§ï¼‰
- é—®é¢˜è¦å…·ä½“ã€æœ‰é’ˆå¯¹æ€§
- ç­”æ¡ˆè¦åŸºäºæ–‡æ¡£å†…å®¹ï¼Œå‡†ç¡®å®Œæ•´
- æŒ‰JSONæ ¼å¼è¾“å‡º

è¯·ç›´æ¥è¾“å‡ºJSONç»“æœï¼š"""

    def _parse_qa_response(self, response: str, chunk_index: int) -> List[Dict[str, Any]]:
        """è§£æAPIå“åº”ä¸­çš„QAå¯¹"""
        try:
            # ğŸ”¥ ä½¿ç”¨GPTResponseParserè¿›è¡Œè§£æ
            qa_pairs = GPTResponseParser.parse_qa_json(
                response, self.api_manager)

            # ä¸ºæ¯ä¸ªQAå¯¹æ·»åŠ chunkç›¸å…³çš„ID
            validated_pairs = []
            for i, qa in enumerate(qa_pairs):
                qa['id'] = f"chunk_{chunk_index}_qa_{i+1}"
                validated_pairs.append(qa)

            if validated_pairs:
                logger.info(
                    f"âœ… ç¬¬{chunk_index}ä¸ªchunkæˆåŠŸç”Ÿæˆ{len(validated_pairs)}ä¸ªQAå¯¹")
                return validated_pairs
            else:
                logger.warning(f"âš ï¸ ç¬¬{chunk_index}ä¸ªchunkæœªç”Ÿæˆæœ‰æ•ˆQAå¯¹")
                return []

        except Exception as e:
            logger.error(f"âŒ ç¬¬{chunk_index}ä¸ªchunk QAè§£æå¼‚å¸¸: {e}")
            return []

    def generate_qa_summary(self, qa_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”ŸæˆQAå¯¹ç»Ÿè®¡æ‘˜è¦"""
        total_chunks = len(qa_results)
        successful_chunks = len(
            [r for r in qa_results if r.get('status') == 'success'])
        total_qa_pairs = sum(len(r.get('qa_pairs', [])) for r in qa_results)

        # æŒ‰ç±»å‹ç»Ÿè®¡
        type_counts = {}
        for result in qa_results:
            for qa in result.get('qa_pairs', []):
                qa_type = qa.get('type', 'unknown')
                type_counts[qa_type] = type_counts.get(qa_type, 0) + 1

        # å¹³å‡ç½®ä¿¡åº¦
        confidences = []
        for result in qa_results:
            for qa in result.get('qa_pairs', []):
                if 'confidence' in qa:
                    confidences.append(qa['confidence'])

        avg_confidence = sum(confidences) / \
            len(confidences) if confidences else 0

        return {
            'total_chunks_processed': total_chunks,
            'successful_chunks': successful_chunks,
            'failed_chunks': total_chunks - successful_chunks,
            'total_qa_pairs': total_qa_pairs,
            'avg_qa_per_chunk': total_qa_pairs / successful_chunks if successful_chunks > 0 else 0,
            'qa_types_distribution': type_counts,
            'average_confidence': round(avg_confidence, 3),
            'success_rate': round(successful_chunks / total_chunks * 100, 2) if total_chunks > 0 else 0
        }
