from elasticsearch import Elasticsearch
from elasticsearch.helpers import bulk
import pandas as pd
import json
from openai import OpenAI
import time
import hashlib

# ç¤ºä¾‹OpenAIå®¢æˆ·ç«¯é…ç½®
client = OpenAI(
    api_key="your_openai_api_key_here",  # æ›¿æ¢ä¸ºä½ çš„å®é™…APIå¯†é’¥
    base_url="https://api.openai.com/v1"  # æˆ–å…¶ä»–å…¼å®¹çš„APIç«¯ç‚¹
)


def get_embedding(input_str):
    """è·å–æ–‡æœ¬çš„å‘é‡åµŒå…¥"""
    response = client.embeddings.create(
        input=input_str,
        model="text-embedding-3-small"  # æˆ–å…¶ä»–åµŒå…¥æ¨¡å‹
    )
    return response.data[0].embedding


def connect_elasticsearch():
    """è¿æ¥Elasticsearch"""
    try:
        es = Elasticsearch(
            hosts=["https://localhost:9200"],  # æ›¿æ¢ä¸ºä½ çš„Elasticsearchä¸»æœºåœ°å€
            basic_auth=('elastic', 'your_elastic_password'),  # æ›¿æ¢ä¸ºä½ çš„å®é™…ç”¨æˆ·åå’Œå¯†ç 
            verify_certs=False,  # âš ï¸ æµ‹è¯•ç¯å¢ƒå¯è®¾ä¸º Falseï¼›ç”Ÿäº§ç¯å¢ƒåº”è®¾ä¸º True å¹¶æä¾› CA è¯ä¹¦
            ssl_show_warn=False,
            request_timeout=30,
            max_retries=3,
            retry_on_timeout=True,
            ssl_assert_hostname=False,
            ssl_assert_fingerprint=False,
            connections_per_node=10,
        )

        if es.ping():
            print("âœ… Elasticsearch è¿æ¥æˆåŠŸ")
            info = es.info()
            print(
                f"ğŸ” é›†ç¾¤åç§°: {info['cluster_name']}, ç‰ˆæœ¬: {info['version']['number']}")
            return es
        else:
            print("âŒ Elasticsearch è¿æ¥å¤±è´¥")
            return None

    except Exception as e:
        print(f"âŒ è¿æ¥ Elasticsearch æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return None


def delete_index(es, index_name):
    """åˆ é™¤ç´¢å¼•"""
    try:
        if es.indices.exists(index=index_name):
            es.indices.delete(index=index_name)
            print(f"âœ… ç´¢å¼• {index_name} å·²åˆ é™¤")
            return True
        else:
            print(f"âš ï¸ ç´¢å¼• {index_name} ä¸å­˜åœ¨")
            return True
    except Exception as e:
        print(f"âŒ åˆ é™¤ç´¢å¼•æ—¶å‡ºé”™: {e}")
        return False


def create_index(es, index_name):
    """åˆ›å»ºç´¢å¼•"""
    try:
        # å®šä¹‰ç´¢å¼•æ˜ å°„
        mapping = {
            "mappings": {
                "properties": {
                    "dense_embedding": {
                        "type": "dense_vector",
                        "dims": 1536,
                        "index": True,
                        "similarity": "cosine"
                    },
                    "procedure": {
                        "type": "text"
                    },
                    "tactics": {
                        "type": "keyword"
                    },
                    "techniques": {
                        "type": "keyword"
                    }
                }
            }
        }

        es.indices.create(index=index_name, body=mapping)
        print(f"âœ… ç´¢å¼• {index_name} åˆ›å»ºæˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»ºç´¢å¼•æ—¶å‡ºé”™: {e}")
        return False


def reindex(es, index_name):
    """é‡æ–°åˆ›å»ºç´¢å¼•"""
    print(f"ğŸ”„ é‡æ–°åˆ›å»ºç´¢å¼•: {index_name}")

    # åˆ é™¤ç°æœ‰ç´¢å¼•
    if not delete_index(es, index_name):
        return False

    # åˆ›å»ºæ–°ç´¢å¼•
    if not create_index(es, index_name):
        return False

    print(f"âœ… ç´¢å¼• {index_name} é‡æ–°åˆ›å»ºå®Œæˆ")
    return True


def generate_doc_id(tactics, techniques, procedure):
    """åŸºäºå†…å®¹ç”Ÿæˆå”¯ä¸€æ–‡æ¡£ID"""
    content_string = f"{tactics}_{techniques}_{procedure}"
    return hashlib.md5(content_string.encode('utf-8')).hexdigest()


def insert_csv_to_es(csv_file_path, index_name="example_ttp_embedding_index", batch_size=100):
    """ä»CSVæ–‡ä»¶è¯»å–æ•°æ®å¹¶æ’å…¥åˆ°Elasticsearch"""

    # è¿æ¥ES
    es = connect_elasticsearch()
    if not es:
        return False

    try:
        # è¯»å–CSVæ–‡ä»¶
        print(f"ğŸ”„ æ­£åœ¨è¯»å–CSVæ–‡ä»¶: {csv_file_path}")

        # ç›´æ¥ä½¿ç”¨utf-8ç¼–ç è¯»å–æ–‡ä»¶ï¼Œé¿å…ç¼–ç æ£€æµ‹é—®é¢˜
        df = pd.read_csv(csv_file_path, encoding='utf-8')

        # æ˜¾ç¤ºCSVæ–‡ä»¶çš„åˆ—åå’Œå‰å‡ è¡Œæ•°æ®
        print(f"ğŸ“Š CSVæ–‡ä»¶åˆ—å: {list(df.columns)}")
        print(f"ğŸ“Š æ•°æ®æ€»è¡Œæ•°: {len(df)}")
        print("ğŸ“Š å‰3è¡Œæ•°æ®é¢„è§ˆ:")
        print(df.head(3))

        # å‡è®¾CSVåˆ—ç»“æ„ä¸ºï¼štactics(åˆ—0), techniques(åˆ—1), procedure(åˆ—2)
        # æ ¹æ®å®é™…CSVæ–‡ä»¶ç»“æ„è°ƒæ•´åˆ—ç´¢å¼•
        tactics_col = df.columns[0]     # ç¬¬ä¸€åˆ—ï¼štactics
        techniques_col = df.columns[1]  # ç¬¬äºŒåˆ—ï¼štechniques
        procedure_col = df.columns[2]   # ç¬¬ä¸‰åˆ—ï¼šprocedure

        # å­˜å‚¨æ‰¹é‡æ’å…¥æ•°æ®
        bulk_data = []
        success_count = 0
        error_count = 0

        print(f"ğŸ”„ å¼€å§‹å¤„ç†æ•°æ®å¹¶ç”Ÿæˆå‘é‡åµŒå…¥...")

        for index, row in df.iterrows():
            try:
                # è·å–è¡Œæ•°æ®
                tactics = str(row[tactics_col]) if pd.notna(
                    row[tactics_col]) else ""
                techniques = str(row[techniques_col]) if pd.notna(
                    row[techniques_col]) else ""
                procedure = str(row[procedure_col]) if pd.notna(
                    row[procedure_col]) else ""

                # è·³è¿‡ç©ºçš„procedure
                if not procedure.strip():
                    print(f"âš ï¸  è·³è¿‡ç¬¬{index+1}è¡Œï¼Œprocedureä¸ºç©º")
                    continue

                # ç”Ÿæˆå”¯ä¸€ID
                doc_id = generate_doc_id(tactics, techniques, procedure)
                print(f"ğŸ”„ å¤„ç†ç¬¬{index+1}è¡Œ: {procedure[:100]}...")

                # è·å–å‘é‡åµŒå…¥
                embedding = get_embedding(procedure)

                # æ„é€ æ’å…¥æ•°æ®
                doc = {
                    "_op_type": "index",
                    "_index": index_name,
                    "_id": doc_id,
                    "_source": {
                        "dense_embedding": embedding,
                        "procedure": procedure,
                        "tactics": tactics,
                        "techniques": techniques
                    }
                }

                bulk_data.append(doc)

                # æ‰¹é‡æ’å…¥
                if len(bulk_data) >= batch_size:
                    try:
                        success, failed = bulk(es, bulk_data)
                        success_count += success
                        error_count += len(failed) if failed else 0
                        print(f"ğŸ“ æ‰¹é‡æ’å…¥å®Œæˆï¼šæˆåŠŸ {success} æ¡")
                        if failed:
                            print(f"âŒ å¤±è´¥ {len(failed)} æ¡")
                    except Exception as bulk_error:
                        print(f"âŒ æ‰¹é‡æ’å…¥å¤±è´¥: {bulk_error}")
                        error_count += len(bulk_data)

                    bulk_data = []  # æ¸…ç©ºç¼“å­˜

                # æ·»åŠ å»¶æ—¶é¿å…APIé™åˆ¶
                time.sleep(1)

            except Exception as row_error:
                print(f"âŒ å¤„ç†ç¬¬{index+1}è¡Œæ—¶å‡ºé”™: {row_error}")
                error_count += 1
                continue

        # æ’å…¥å‰©ä½™æ•°æ®
        if bulk_data:
            try:
                success, failed = bulk(es, bulk_data)
                success_count += success
                error_count += len(failed) if failed else 0
                print(f"ğŸ“ æœ€åæ‰¹æ¬¡æ’å…¥å®Œæˆï¼šæˆåŠŸ {success} æ¡")
                if failed:
                    print(f"âŒ å¤±è´¥ {len(failed)} æ¡")
            except Exception as bulk_error:
                print(f"âŒ æœ€åæ‰¹æ¬¡æ’å…¥å¤±è´¥: {bulk_error}")
                error_count += len(bulk_data)

        print(f"ğŸ‰ æ•°æ®æ’å…¥å®Œæˆï¼")
        print(f"âœ… æˆåŠŸæ’å…¥: {success_count} æ¡")
        print(f"âŒ å¤±è´¥: {error_count} æ¡")
        return True

    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {csv_file_path}")
    except UnicodeDecodeError as e:
        print(f"âŒ æ–‡ä»¶ç¼–ç é”™è¯¯: {e}")
        print("ğŸ’¡ æç¤º: å°è¯•ä½¿ç”¨ä¸åŒçš„ç¼–ç æ–¹å¼ï¼Œå¦‚ 'utf-8', 'gbk', 'latin1' ç­‰")
    except Exception as e:
        print(f"âŒ è¯»å–CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    return False


def main():
    print("ğŸš€ å¼€å§‹ä»CSVæ–‡ä»¶æ’å…¥æ•°æ®åˆ°Elasticsearch...")

    # æ’å…¥æ•°æ®
    insert_csv_to_es("./example_ttp_data.csv", "example_ttp_embedding_index", 50)


if __name__ == "__main__":
    main()