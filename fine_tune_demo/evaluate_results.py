#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯„ä¼°çŸ¥è¯†å›¾è°±æå–æ¨¡å‹çš„æ¨ç†ç»“æœè´¨é‡
"""

import json
import logging
from typing import Dict, List, Any
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class KGEvaluation:
    """çŸ¥è¯†å›¾è°±æ¨ç†ç»“æœè¯„ä¼°å™¨"""

    def __init__(self, results_file: str):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨

        Args:
            results_file: è¯„ä¼°ç»“æœæ–‡ä»¶è·¯å¾„
        """
        self.results_file = Path(results_file)
        self.evaluation_data = None
        self.load_results()

    def load_results(self):
        """åŠ è½½è¯„ä¼°ç»“æœæ•°æ®"""
        try:
            with open(self.results_file, 'r', encoding='utf-8') as f:
                self.evaluation_data = json.load(f)
            logger.info(f"âœ… æˆåŠŸåŠ è½½è¯„ä¼°ç»“æœ: {self.results_file}")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è¯„ä¼°ç»“æœå¤±è´¥: {e}")
            raise

    def evaluate_entity_extraction(self, parsed_json: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¯„ä¼°å®ä½“æå–è´¨é‡

        Args:
            parsed_json: è§£æåçš„JSONæ•°æ®

        Returns:
            è¯„ä¼°ç»“æœ
        """
        entities = parsed_json.get('entities', [])
        
        # ç»Ÿè®¡å„ç±»å®ä½“æ•°é‡
        entity_types = {}
        for entity in entities:
            label = entity.get('labels', 'Unknown')
            entity_types[label] = entity_types.get(label, 0) + 1
        
        return {
            'total_entities': len(entities),
            'entity_types': entity_types
        }

    def evaluate_relationship_extraction(self, parsed_json: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¯„ä¼°å…³ç³»æå–è´¨é‡

        Args:
            parsed_json: è§£æåçš„JSONæ•°æ®

        Returns:
            è¯„ä¼°ç»“æœ
        """
        relationships = parsed_json.get('relationships', [])
        
        # ç»Ÿè®¡å„ç±»å…³ç³»æ•°é‡
        relationship_types = {}
        for rel in relationships:
            rel_type = rel.get('type', 'Unknown')
            relationship_types[rel_type] = relationship_types.get(rel_type, 0) + 1
        
        return {
            'total_relationships': len(relationships),
            'relationship_types': relationship_types
        }

    def evaluate_json_structure(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¯„ä¼°JSONç»“æ„è´¨é‡

        Args:
            result: å•ä¸ªæµ‹è¯•ç»“æœ

        Returns:
            è¯„ä¼°ç»“æœ
        """
        return {
            'json_parse_success': result.get('json_parse_success', False),
            'has_entities': 'entities' in result.get('parsed_json', {}),
            'has_relationships': 'relationships' in result.get('parsed_json', {}),
            'entities_not_empty': len(result.get('parsed_json', {}).get('entities', [])) > 0,
            'relationships_not_empty': len(result.get('parsed_json', {}).get('relationships', [])) > 0
        }

    def comprehensive_evaluation(self) -> Dict[str, Any]:
        """
        ç»¼åˆè¯„ä¼°æ‰€æœ‰æµ‹è¯•ç»“æœ

        Returns:
            ç»¼åˆè¯„ä¼°ç»“æœ
        """
        if not self.evaluation_data:
            logger.error("âŒ è¯„ä¼°æ•°æ®æœªåŠ è½½")
            return {}

        detailed_results = self.evaluation_data.get('detailed_results', [])
        
        # æ€»ä½“ç»Ÿè®¡
        total_tests = len(detailed_results)
        json_success_count = 0
        entity_count = 0
        relationship_count = 0
        
        # ç±»å‹ç»Ÿè®¡
        all_entity_types = {}
        all_relationship_types = {}
        
        # é€é¡¹è¯„ä¼°
        evaluation_details = []
        for i, result in enumerate(detailed_results, 1):
            logger.info(f"ğŸ” è¯„ä¼°æµ‹è¯•é¡¹ {i}/{total_tests}")
            
            # JSONç»“æ„è¯„ä¼°
            json_eval = self.evaluate_json_structure(result)
            
            if json_eval['json_parse_success']:
                json_success_count += 1
                
                parsed_json = result.get('parsed_json', {})
                
                # å®ä½“æå–è¯„ä¼°
                entity_eval = self.evaluate_entity_extraction(parsed_json)
                entity_count += entity_eval['total_entities']
                
                # å…³ç³»æå–è¯„ä¼°
                rel_eval = self.evaluate_relationship_extraction(parsed_json)
                relationship_count += rel_eval['total_relationships']
                
                # åˆå¹¶ç±»å‹ç»Ÿè®¡
                for etype, count in entity_eval['entity_types'].items():
                    all_entity_types[etype] = all_entity_types.get(etype, 0) + count
                    
                for rtype, count in rel_eval['relationship_types'].items():
                    all_relationship_types[rtype] = all_relationship_types.get(rtype, 0) + count
                
                evaluation_details.append({
                    'test_index': i,
                    'json_structure': json_eval,
                    'entity_extraction': entity_eval,
                    'relationship_extraction': rel_eval
                })
        
        # è®¡ç®—æˆåŠŸç‡
        json_success_rate = json_success_count / total_tests if total_tests > 0 else 0
        
        # ç»¼åˆè¯„ä¼°ç»“æœ
        comprehensive_result = {
            'summary': {
                'total_tests': total_tests,
                'json_parse_success_count': json_success_count,
                'json_parse_success_rate': json_success_rate,
                'total_entities_extracted': entity_count,
                'total_relationships_extracted': relationship_count,
                'average_entities_per_test': entity_count / total_tests if total_tests > 0 else 0,
                'average_relationships_per_test': relationship_count / total_tests if total_tests > 0 else 0
            },
            'entity_types_distribution': all_entity_types,
            'relationship_types_distribution': all_relationship_types,
            'detailed_evaluations': evaluation_details
        }
        
        return comprehensive_result

    def generate_report(self, output_file: str = None) -> str:
        """
        ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š

        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰

        Returns:
            è¯„ä¼°æŠ¥å‘Šå†…å®¹
        """
        evaluation_result = self.comprehensive_evaluation()
        
        if not evaluation_result:
            return "æ— æ³•ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"
        
        summary = evaluation_result['summary']
        entity_types = evaluation_result['entity_types_distribution']
        rel_types = evaluation_result['relationship_types_distribution']
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("çŸ¥è¯†å›¾è°±æå–æ¨¡å‹è¯„ä¼°æŠ¥å‘Š")
        report_lines.append("=" * 60)
        report_lines.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        report_lines.append("æ€»ä½“ç»Ÿè®¡:")
        report_lines.append(f"  - æµ‹è¯•æ ·æœ¬æ•°: {summary['total_tests']}")
        report_lines.append(f"  - JSONè§£ææˆåŠŸç‡: {summary['json_parse_success_rate']:.2%} ({summary['json_parse_success_count']}/{summary['total_tests']})")
        report_lines.append(f"  - æ€»å®ä½“æ•°: {summary['total_entities_extracted']}")
        report_lines.append(f"  - æ€»å…³ç³»æ•°: {summary['total_relationships_extracted']}")
        report_lines.append(f"  - å¹³å‡æ¯æ ·æœ¬å®ä½“æ•°: {summary['average_entities_per_test']:.2f}")
        report_lines.append(f"  - å¹³å‡æ¯æ ·æœ¬å…³ç³»æ•°: {summary['average_relationships_per_test']:.2f}")
        report_lines.append("")
        
        # å®ä½“ç±»å‹åˆ†å¸ƒ
        report_lines.append("å®ä½“ç±»å‹åˆ†å¸ƒ:")
        for etype, count in sorted(entity_types.items(), key=lambda x: x[1], reverse=True):
            report_lines.append(f"  - {etype}: {count}")
        report_lines.append("")
        
        # å…³ç³»ç±»å‹åˆ†å¸ƒ
        report_lines.append("å…³ç³»ç±»å‹åˆ†å¸ƒ:")
        for rtype, count in sorted(rel_types.items(), key=lambda x: x[1], reverse=True):
            report_lines.append(f"  - {rtype}: {count}")
        report_lines.append("")
        
        report_content = "\n".join(report_lines)
        
        # è¾“å‡ºåˆ°æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if output_file:
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(report_content)
                logger.info(f"âœ… è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
            except Exception as e:
                logger.error(f"âŒ ä¿å­˜è¯„ä¼°æŠ¥å‘Šå¤±è´¥: {e}")
        
        return report_content


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹è¯„ä¼°çŸ¥è¯†å›¾è°±æå–æ¨¡å‹æ¨ç†ç»“æœ")
    
    # è¯„ä¼°ç»“æœæ–‡ä»¶è·¯å¾„
    results_file = "./fine_tune_output/evaluation_results.json"
    
    try:
        # åˆå§‹åŒ–è¯„ä¼°å™¨
        evaluator = KGEvaluation(results_file)
        
        # ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
        report = evaluator.generate_report("./fine_tune_output/automatic_evaluation_report.txt")
        print(report)
        
        logger.info("âœ… è¯„ä¼°å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise


if __name__ == "__main__":
    main()